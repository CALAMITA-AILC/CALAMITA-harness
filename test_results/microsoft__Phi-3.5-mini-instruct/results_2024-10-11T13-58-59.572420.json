{
  "results": {
    "en_it_public": {
      "alias": "en_it_public",
      "bleu_score,none": 0.3359118712843561,
      "bleu_score_stderr,none": 0.052769912757308614,
      "chrf_score,none": 63.98654367382747,
      "chrf_score_stderr,none": 3.37978434222762,
      "bleurt_score,none": 0.3574715256690979,
      "bleurt_score_stderr,none": 0.1188997710291865,
      "comet_score,none": 0.8630931079387665,
      "comet_score_stderr,none": 0.015811795238082335
    }
  },
  "group_subtasks": {
    "en_it_public": []
  },
  "configs": {
    "en_it_public": {
      "task": "en_it_public",
      "dataset_path": "FBK-MT/MT-benchmark4CALAMITA2024",
      "validation_split": "devtest",
      "test_split": "devtest",
      "process_docs": "def preprocess_dataset(dataset: datasets.Dataset) -> datasets.Dataset:\n    dataset = dataset.select([i for i in range(4)])      # selecting 4 rows for DEBUG\n    # print(dataset)\n    # exit()\n    return dataset\n",
      "doc_to_text": "Translate the following sentence into English: <Nella giornata di lunedì, alcuni scienziati della Scuola di Medicina dell'Università di Stanford hanno annunciato l'invenzione di un nuovo strumento diagnostico capace di ordinare le cellule in base al tipo: un chip minuscolo che può essere stampato utilizzando stampanti a getto di inchiostro al costo di circa 1 centesimo di dollaro l'uno.>\n<On Monday, scientists from the Stanford University School of Medicine announced the invention of a new diagnostic tool that can sort cells by type: a tiny printable chip that can be manufactured using standard inkjet printers for possibly about one U.S. cent each.>\n\nTranslate the following sentence into English: <Secondo i responsabili della ricerca questo strumento potrebbe consentire diagnosi precoci di cancro, tubercolosi, HIV e malaria per i malati che vivono in Paesi a basso reddito. In alcuni di questi Paesi il tasso di sopravvivenza legati a patologie come il cancro al seno può essere addirittura la metà rispetto a quello registrato nei Paesi più abbienti.>\n<Lead researchers say this may bring early detection of cancer, tuberculosis, HIV and malaria to patients in low-income countries, where the survival rates for illnesses such as breast cancer can be half those of richer countries.>\n\nTranslate the following sentence into English: <Il JAS 39C Gripen è precipitato su una pista di atterraggio alle 9:30 circa, ora locale (02:30 UTC), ed è esploso, con la conseguente chiusura dell’aeroporto ai voli commerciali.>\n<The JAS 39C Gripen crashed onto a runway at around 9:30 am local time (0230 UTC) and exploded, closing the airport to commercial flights.>\n\nTranslate the following sentence into English: <L'identificazione del pilota ha rivelato che si trattava del capo squadriglia Dilokrit Pattavee.>\n<The pilot was identified as Squadron Leader Dilokrit Pattavee.>\n\nTranslate the following sentence into English: <{{italian}}>",
      "doc_to_target": "{{english}}",
      "process_results": "def process_results_gen(doc, results):\n    \"\"\"\n    Process the results of the model and return the metrics\n    Args:\n        - doc: the document containing the input and output (keys are the variables from the prompt_template)\n        - results: the output of the model (still dunnow why its a list but it doesn't depend on the batchsize)\n    Returns:\n        - a dictionary containing the metrics (metric_name: metric_value)\n    \"\"\"\n\n    completion = results[0]\n    model_input, reference_out = doc[\"italian\"], doc[\"english\"]\n\n    # clean completion\n    completion = _search_delimiters(completion)\n\n    # BLEU\n    bleu_score = single_bleu(ref=reference_out, pred=completion)\n    # CHRF\n    chrf_score = sigle_chrf(ref=reference_out, pred=completion)\n    # BLEURT\n    bleurt_score = single_bleurt(ref=reference_out, pred=completion)\n    # COMET\n    comet_score = single_comet(source=model_input, ref=reference_out, pred=completion)\n\n\n    # print(\"========================================================\")\n    # print(\"model_input: \", model_input)\n    # print(\"expected: \", reference_out)\n    # print(\"completion: \", completion)\n    # print(\"BLEU: \", bleu_score)\n    # print(\"CHRF: \", chrf_score)\n    # print(\"BLEURT: \", bleurt_score)\n    # print(\"COMET: \", comet_score)\n    # print(\"========================================================\")\n\n    return {\n        \"bleu_score\": bleu_score,\n        \"chrf_score\": chrf_score,\n        \"bleurt_score\": bleurt_score,\n        \"comet_score\": comet_score,\n    }\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "bleu_score",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "chrf_score",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "bleurt_score",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "comet_score",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "generate_until",
      "generation_kwargs": {
        "until": [
          "\n\n"
        ],
        "do_sample": false
      },
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    }
  },
  "versions": {
    "en_it_public": 1.0
  },
  "n-shot": {
    "en_it_public": 0
  },
  "higher_is_better": {
    "en_it_public": {
      "bleu_score": true,
      "chrf_score": true,
      "bleurt_score": true,
      "comet_score": true
    }
  },
  "n-samples": {
    "en_it_public": {
      "original": 4,
      "effective": 4
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=microsoft/Phi-3.5-mini-instruct",
    "model_num_parameters": 3821079552,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0",
    "batch_size": "2",
    "batch_sizes": [],
    "device": "mps",
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "06f38231",
  "date": 1728647787.806266,
  "pretty_env_info": "PyTorch version: 2.4.1\nIs debug build: False\nCUDA used to build PyTorch: None\nROCM used to build PyTorch: N/A\n\nOS: macOS 15.0.1 (arm64)\nGCC version: Could not collect\nClang version: 16.0.0 (clang-1600.0.26.3)\nCMake version: Could not collect\nLibc version: N/A\n\nPython version: 3.11.7 (main, Jan 13 2024, 17:16:06) [Clang 15.0.0 (clang-1500.1.0.2.5)] (64-bit runtime)\nPython platform: macOS-15.0.1-arm64-arm-64bit\nIs CUDA available: False\nCUDA runtime version: No CUDA\nCUDA_MODULE_LOADING set to: N/A\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nApple M1 Max\n\nVersions of relevant libraries:\n[pip3] mypy-extensions==1.0.0\n[pip3] numpy==1.26.3\n[pip3] optree==0.10.0\n[pip3] pytorch-lightning==2.4.0\n[pip3] torch==2.4.1\n[pip3] torchmetrics==0.10.3\n[pip3] torchvision==0.19.1\n[conda] Could not collect",
  "transformers_version": "4.44.2",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<|endoftext|>",
    "32000"
  ],
  "tokenizer_eos_token": [
    "<|endoftext|>",
    "32000"
  ],
  "tokenizer_bos_token": [
    "<s>",
    "1"
  ],
  "eot_token_id": 32000,
  "max_length": 131072,
  "task_hashes": {
    "en_it_public": "55c6c09f0d7a4eca74cb0e03514571195556d9adb322a6dc3b93a937660551a7"
  },
  "model_source": "hf",
  "model_name": "microsoft/Phi-3.5-mini-instruct",
  "model_name_sanitized": "microsoft__Phi-3.5-mini-instruct",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 451718.094092,
  "end_time": 451873.930772708,
  "total_evaluation_time_seconds": "155.8366807079874"
}